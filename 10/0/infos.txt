Introduction: However to do so agent plans must be capable of representing the myriad of actions and control flows required to perform those tasks In addition since these tasks can require integrating multiple sources of remote information  typically a slow IObound process  it is desirable to make execution as efficient as possible To address both of these needs we present a flexible software agent plan language and a highly parallel execution system that enable the efficient execution of expressive agent plans The plan language allows complex tasks to be more easily expressed by providing a variety of operators for flexibly processing the data as well as supporting subplans  and recursion  The executor is based on a streaming dataflow model of execution to maximize the amount of operator and data parallelism possible at runtime We have implemented both the language and executor in a system called THESEUS Our results from testing THESEUS show that streaming dataflow execution can yield significant speedups over both traditional serial  as well as nonstreaming dataflowstyle execution that existing software and robot agent execution systems currently support In addition we show how plans written in the language we present can represent certain types of subtasks that cannot be accomplished using the languages supported by network query engines Finally we demonstrate that the increased expressivity of our plan language does not hamper performance specifically we show how data can be integrated from multiple remote sources just as efficiently using our architecture as is possible with a stateoftheart streamingdataflow network query engine 1 Introduction The goal of software agents is to automate tasks that require interacting with one or more accessible software systems Furthermore the Web is ripe for such automation  given the sheer number of online applications and the complete lack of coordination between them agents could address an endless list of needs and problems to be solved for people that do use the Web for practical purposes Furthermore like other software agent domains Web tasks vary widely in complexity and by definition involve routing and processing information as part of the task In this paper we describe a software agent plan language and execution system that enables one to express a wide range of tasks as a software agent plan and then to have that plan be efficiently executed We have implemented both the language and the executor in a system called THESEUS Throughout this paper we will discuss THESEUS in the context of Web information gathering and processing since the Web represents a domain where most  of the challenges that software agents face can be found 11 Web Information Agents The degree of complexity in gathering information from the Web varies significantly Some types of tasks can be accomplished manually because the size of the data gathered is small or the need to query is infrequent For example finding the address of a restaurant or a theater in a particular city using a Yellow Pages type of Web site is easy enough for people to do themselves It does not need to be automated since the query need only be done once and the result returned is small and easy to manage However not all information gathering tasks are as simple There are often times when the amount of data involved is large or the answer requires integrating data from multiple sites or the answer requires multiple queries over a period of time For example consider shopping for an expensive product over a period of time using multiple sources that are each updated daily Such tasks can become quickly tedious and require a greater amount of manual work making them very desirable to automate 111 MORE One type of difficult Web information gathering task involves interleaved gathering and navigation For the benefit of people that use a Web browser to access online data many Web sources display large sets of query results spread over a series of web pages connected through Next Page links For example querying an online classified listings source for automobiles for sale can generate many results Instead of displaying the results on a single very long Web page many classified listings sites group sets of results over series of hyperlinked pages In order to automatically collect this data a system needs to interleave navigation and gathering an AN EXPRESSIVE LANGUAGE AND EFFICIENT EXECUTION SYSTEM FOR SOFTWARE AGENTS 627 indeterminate number of times that is it needs to collect results from a given page navigate to the next gather the next set of results navigate and so on until it reaches the end of set of results While there has been some work addressing how to theoretically incorporate navigation into the gathering process  no attention has been given to the efficient execution of plans that engage in this type of interleaved retrieval A second example has to do with monitoring a Web source Since the Web does not contain a builtin trigger facility one is forced to manually check sources for updated data When updates are frequent or the need to identify an update immediately is urgent it becomes desirable to automate the monitoring of these updates notifying the user when one or more conditions are met For example suppose we want to be alerted as soon as a particular type of used car is listed for sale by one or more online classified ad sources Repeated manual checking for such changes is obviously tedious Mediators and network query engines can automate the query but additional software in programming languages such as Java or C must be written to handle the monitoring process itself something that requires conditional execution comparison with past results possible notification of the user and other such actions 112
Problem and Solution: The degree of complexity in gathering information from the Web varies significantly Some types of tasks can be accomplished manually because the size of the data gathered is small or the need to query is infrequent For example finding the address of a restaurant or a theater in a particular city using a Yellow Pages type of Web site is easy enough for people to do themselves It does not need to be automated since the query need only be done once and the result returned is small and easy to manage However not all information gathering tasks are as simple There are often times when the amount of data involved is large or the answer requires integrating data from multiple sites or the answer requires multiple queries over a period of time For example consider shopping for an expensive product over a period of time using multiple sources that are each updated daily Such tasks can become quickly tedious and require a greater amount of manual work making them very desirable to automate 111 MORE One type of difficult Web information gathering task involves interleaved gathering and navigation For the benefit of people that use a Web browser to access online data many Web sources display large sets of query results spread over a series of web pages connected through Next Page links For example querying an online classified listings source for automobiles for sale can generate many results Instead of displaying the results on a single very long Web page many classified listings sites group sets of results over series of hyperlinked pages In order to automatically collect this data a system needs to interleave navigation and gathering an AN EXPRESSIVE LANGUAGE AND EFFICIENT EXECUTION SYSTEM FOR SOFTWARE AGENTS 627 indeterminate number of times that is it needs to collect results from a given page navigate to the next gather the next set of results navigate and so on until it reaches the end of set of
Conclusion: Though we have demonstrated that THESEUS performs well on more complex information gathering tasks it is useful to assess whether the increased expressivity in THESEUS impacts its performance on simpler tasks  in particular ones that network query engines typically process To do this we explored the performance of THESEUS on a more traditional database style query plan for online information gathering and compared it to the same type of plan executed by a network query engine We chose a single common type of SPJ query that involved multiple data sources to serve as the basis for comparison This is the canonical data integration query We claim that understanding how THESEUS compares to a network query engine with respect to the performance of an SPJ query is at the heart of the efficiency comparison between the two types of systems Since both types of systems execute dataflowstyle plans in pipelined fashion theoretical performance should be the same  the only expected differences would be due to implementation or environment biases eg different LAN infrastructures Nevertheless to support our efficiency claim we felt it was important to use a concrete SPJ query for comparison For our experiment we chose to reproduce a query from the paper of another network query engine  Telegraph To measure the performance of their partial results query processing technique Raman and Hellerstein ran a query that gathered data from three sources and then joined them together  The specific query involved gathering information on contributors to the 2000 US Presidential campaign and then combined this information with neighborhood demographic information and crime index information  lists the sources and the data they provide Bulk scannable sources are those where the data to be extracted can be read directly ie exists on a static Web page or file Index sources are those that provide answers based on queries via Web forms Index sources are thus sources which require binding patterns  shows the query that was used to evaluate the performance of TELEGRAPH It is important to note that Raman and Hellerstein measured the performance of the query in  under standard pipelined mode and compared this with their JuggleEddy partial results approach We are only interested in the results of the former as this is a measure of how well an unoptimized network query engine  what we call the baseline  gathers data when processing a traditional databasestyle query Any further optimization such as the JuggleEddy is complementary to the system described here Since both types of systems rely on streaming dataflow execution consisting of tuples routed through iterativestyle query operators it would not be difficult to extend THESEUS to support this and other types of adaptive query processing techniques Source Site Type of data FEC  Bulk scannable source that provides information  on each contributor to a candidate in the 2000 Presidential campaign Yahoo Real Estate realestsateyahoocom Index source that returns neighborhood demographic information for a particular zip code Crime  Index source that returns crime level ratings for a particular zip code  Sources used in the FECYahooCrime query BARISH  KNOBLOCK 656 We wrote a simple THESEUS plan that allowed the query in  to be executed We used exactly the same sources except we found that the latency of the Crime source had increased substantially as compared to the times recorded by Raman and Hellerstein Instead we used another source  but added an artificial delay to each tuple processed by that source so that the new source performed similarly Raman and Hellersteins results show that the performance of their pipeline plan was as slow as the Crime source and about 250ms per tuple To match this we added a 150ms delay to each tuple of processing for our new source Yahoo which was normally fetching data at about 100ms per tuple Our results are shown in  The results show that THESEUS was not only able to execute the same plan at least as fast as the baseline TELEGRAPH plan the nonoptimized result shown in  of the paper by Raman and Hellerstein but THESEUS execution can be more efficient depending on the number of threads in the thread pool For example THESEUS3 describes the case where the THESEUS thread pool contains 3 threads The result from this run performs slightly worse than the TELEGRAPH baseline  such minor differences could be due to changes in source behavior or in different proximities to network sources However running THESEUS with more threads in the thread pool ie THESEUS6 and THESEUS10 shows much better performance This is because the degree of vertical parallelism demanded during execution can be better accommodated with more threads It should be noted that the reason TELEGRAPH does not perform as well as THESEUS6 and THESEUS10 is likely because that system only assigned a single thread to each operator  That is THESEUS6 and THESEUS10 execution involves 6 and 10 concurrent threads respectively whereas the TELEGRAPH plan uses 3 concurrent threads 7 Related Work The language and system discussed in this paper are relevant to other efforts that focus on agent execution and the querying of Web data To understand the work presented here in the context of these other approaches we consider past work in software agent execution robot agent execution and network query engines The first area is most relevant as software agent systems have Query SELECT FName CCrime Yincome FROM FEC as F Crime as C Yahoo as Y WHERE Fzip  Yzip and Fzip  Czip  SQL query that associates crime and income statistics with political campaign contributions  Comparing THESEUS to TELEGRAPH baseline FECYahooCrime 0 20000 40000 60000 80000 100000 120000 140000 160000 180000 200000 0 2000 4000 6000 8000 10000 12000 Time  Cell updates Theseus10 Theseus6 Telegraph Theseus3 AN EXPRESSIVE LANGUAGE AND EFFICIENT EXECUTION SYSTEM FOR SOFTWARE AGENTS 657 historically addressed expressivity issues and in recent years have also attempted to address some of the efficiency issues Robot plan executors represent a slightly greater contrast that have less experience with processing large amounts of data On the other hand network query engines have explored largescale remote data processing though planquery expressivity tends to be quite narrow 71 Software Agent Execution Systems The Internet Softbot  is a software agent that automates various information processing tasks including UNIX command processing and Web information gathering To support execution with incomplete information about the world the system interleaves planning with execution The XII Golden et al 1994 and later Puccini  planners generate partiallyordered plans in which the effects of an action do not have to be known before execution  but which can be verified during execution While the Softbot makes a clear distinction between information goals and satisfaction goals it does not specifically address the need to efficiently nor flexibly handle the information it processed For example the system does not support any kind of parallel processing of information to capitalize on the IObound nature of execution In terms of expressivity while XII and Puccini do allow universal quantification to be expressed ie iteration is possible to do so requires that the set of what is being iterated over be known in advance As we pointed out in an earlier example on Next Page links this is not always the case  the set of next pages to be processed are only discovered by iterating through all of them in an indeterminate dowhile fashion In contrast although it does not interleave planning and execution the system described here does support a more expressive plan language capable of handling nextlink type of processing as well as a streaming dataflow model of execution that enables efficient large scale information processing To a great extent contributions of both research efforts can be viewed as complementary Other research such as INFOSLEUTH Bayardo et al 1997 has recognized the importance of concurrent taskaction execution close to the spirit of true dataflow computing At the same time such work has generally not investigated the impact of streaming combined with dataflow INFOSLEUTH describes a collection of agents that when combined and working together present a cohesive view of data integration across multiple heterogeneous sources INFOSLEUTH centralizes execution in its Task Execution Agent which coordinates highlevel information gathering subtasks necessary to fulfill user queries by routing appropriate queries to resources that can accommodate those queries The Task Execution Agent is datadriven and thus task fulfillment proceeds in a dataflowstyle manner In addition a multithreading architecture supports concurrent asynchronous communication between agents However the streaming component does not exist  in fact while INFOSLEUTH intends to do large scale information processing it specifically notes that limitations to KQML  were such that streaming was not feasible at the time of implementation Both INFOSLEUTH and THESEUS are similar in their desire to support efficient largescale information processing However THESEUS supports streaming between operators as well as a more expressive plan language capable of support for more complex types of plans including support for conditionals and recursion In contrast to INFOSLEUTH BIG  is a more general software agent that separates the components of agent planning scheduling and execution  BIG agents execute plans based on tasks modeled in the TÆMS modeling language During execution BIG reasons about resource tradeoffs and attempts to parallelize nonlocal requests  at least in terms of how such actions are scheduled In terms of expressivity TÆMS does not include support for conditionals or looping constructs  unlike the system described in this paper